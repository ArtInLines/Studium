{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 0\n",
    "from IPython.core.display import HTML, display\n",
    "display(HTML('<style>.container { width:100%; !important } </style>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Local Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows one important application of <em style=\"color:blue;\">dictionaries</em> and <em style=\"color:blue;\">sets</em>:\n",
    "It implements a *local search engine* that can be used to index `.pdf` documents on the local file system.  The index can then be used to search for all documents that contain specified words.  The main data structure used is a so called \n",
    "<em style=\"color:blue;\">inverted index</em>, which is a <em style=\"color:blue;\">dictionary</em> mapping words to the \n",
    "<em style=\"color:blue;\">sets</em> of documents that contain these words.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The module `subprocess` enables us to execute shell command and to capture their output via a *pipe* from which we can read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `get_text` takes a `path` specifiying a `.pdf` file.  It converts the `.pdf` file into a text file and returns the \n",
    "resulting text.  This function assumes that the program `pdftotext` is installed.  This program can be dowloaded at\n",
    "<a href=\"https://www.xpdfreader.com/download.html\">https://www.xpdfreader.com/download.html</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(path):\n",
    "    command = ['pdftotext', '-enc', 'UTF-8', '-q', path, '-']\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE)\n",
    "    Lines   = process.stdout.readlines()\n",
    "    return ''.join([str(line, 'utf-8', 'ignore') for line in Lines])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test this for one file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "text = get_text('../Literature/DualPivotQuicksort.pdf')\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to split the text contained in a file into words, we need the *regular expressions* provided by the module `re`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `tokenize` takes a string `s` and returns the set of words that have been found in the string `s`.  We assume that the words contain only latin characters.  Furthermore, we convert the words to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    return set(t.lower() for t in re.findall(r'[A-Za-z]+', s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check how many different words occur in the file that we have read above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the module `os` to traverse directories.  `os` is short for *operating system*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `Document` represents a single file.  This class maintains three member variables:\n",
    "  - `path`  is the absolut file path specifying the location of the file containing the `pdf` document,\n",
    "  - `docID` is a natural number that serves as a unique identifier for the document,\n",
    "  - `Words` is the set of words contained in the file.\n",
    "  \n",
    "This class only serves as a container of its member variables, hence it has no methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, path, docID, Words):\n",
    "        self.path  = path\n",
    "        self.docID = docID\n",
    "        self.Words = Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `Index` contains three member variables:\n",
    "  - `InvertedIndex` is a dictionary that maps every word to the set of documents containing this word.\n",
    "    In this set, the documents are represented by their unique identifiers.\n",
    "  - `ID2Doc` is a dictionary mapping the document identifiers to the corresponding `Document` objects.\n",
    "  - `fileCount` is a counter that is needed to create unique document identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index:\n",
    "    def __init__(self):\n",
    "        self.InvertedIndex = {}\n",
    "        self.ID2Doc        = {}\n",
    "        self.fileCount     = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method $\\texttt{self}.\\texttt{buildIndex}(d)$ takes an `Index` $\\texttt{self}$ and a directory $d$.  It traverses the directory $d$ recursively and collects all `.pdf` files contained in $d$ and its subdirectories.  These files are converted to text and their words are added to the `InvertedIndex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildIndex(self, directory):   \n",
    "    for root, _, files in os.walk(directory):\n",
    "        for fileName in files:\n",
    "            if fileName[-4:] == '.pdf':\n",
    "                fullpath = os.path.abspath(os.path.join(root, fileName))\n",
    "                print('indexing', fullpath, end=' has ')\n",
    "                try:\n",
    "                    fileText = get_text(fullpath)\n",
    "                    tokenSet = tokenize(fileText)\n",
    "                    print(len(tokenSet), 'different words.')\n",
    "                    self.fileCount += 1\n",
    "                    document = Document(fullpath, self.fileCount, tokenSet)\n",
    "                    self.ID2Doc[self.fileCount] = document\n",
    "                    self._addToIndex(self.fileCount, tokenSet)\n",
    "                except:\n",
    "                    print('unable to read', path)\n",
    "                    continue\n",
    "        \n",
    "Index.buildIndex = buildIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `_addToIndex` takes a document identifier $d$ and a set of words $W$ occurring in the document specified by $d$ and extends the `InvertedIndex` so that for every word $w$ in `Words` we have that\n",
    "$$ d \\in \\texttt{InvertedIndex}[w]. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _addToIndex(self, documentID, Words):\n",
    "    for term in Words:\n",
    "        try:\n",
    "            docSet = self.InvertedIndex[term]\n",
    "            docSet.add(documentID)\n",
    "        except KeyError:\n",
    "            self.InvertedIndex[term] = { documentID }\n",
    "        \n",
    "Index._addToIndex = _addToIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us build an `Index` for a directory containing some literature regarding my lectures on algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "index = Index()\n",
    "index.buildIndex(\"../Literature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method $\\texttt{self}.\\texttt{retrieve}(Q)$ takes an Index `self` and a query $Q$.  $Q$ is a string containing multiple words. \n",
    "The method returns the set of those documents that contain all the words occurring in $Q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(self, Query):\n",
    "    SearchStrings = list(tokenize(Query))\n",
    "    result        = set()\n",
    "    Documents     = self.InvertedIndex.get(SearchStrings[0], set())\n",
    "    for word in SearchStrings[1:]:\n",
    "        Documents &= self.InvertedIndex.get(word, set())           \n",
    "    return { self.ID2Doc[docID].path for docID in Documents }\n",
    "\n",
    "Index.retrieve = retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "index.retrieve(\"trie avl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
